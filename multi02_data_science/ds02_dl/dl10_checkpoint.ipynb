{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e049248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a445db7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43152e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_scale = x_train / 255.0\n",
    "x_test_scale = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1a9c02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Flatten(),\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(32, activation=\"relu\"),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afa90af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "410e207a",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"dl10_checkpoints\"\n",
    "if os.path.exists(save_dir):\n",
    "    pass\n",
    "else:\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f893e27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/2025_10_27_14_31'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "save_time = f\"/{now.year}_{now.month}_{now.day}_{now.hour}_{now.minute}\"\n",
    "save_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6b8132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .h5 (옛날 버전) -> .keras (현재)\n",
    "# save_best_only  : True 로스값이 가장 낮을때만 저장하겠다. 내려가다가 다시 올라간 지점은 저장하지 않겠다.\n",
    "# save_best_only  : False로 저장하면 모두 저장된다.\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=save_dir + save_time + \"_{epoch}_{val_loss:.4f}.keras\", monitor=\"val_loss\", save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f12a4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.6472 - loss: 1.1714 - val_acc: 0.9078 - val_loss: 0.3285\n",
      "Epoch 2/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - acc: 0.9046 - loss: 0.3317 - val_acc: 0.9159 - val_loss: 0.2843\n",
      "Epoch 3/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - acc: 0.9174 - loss: 0.2864 - val_acc: 0.9231 - val_loss: 0.2636\n",
      "Epoch 4/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.9230 - loss: 0.2706 - val_acc: 0.9290 - val_loss: 0.2487\n",
      "Epoch 5/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - acc: 0.9246 - loss: 0.2583 - val_acc: 0.9277 - val_loss: 0.2468\n",
      "Epoch 6/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9278 - loss: 0.2478 - val_acc: 0.9300 - val_loss: 0.2450\n",
      "Epoch 7/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - acc: 0.9311 - loss: 0.2331 - val_acc: 0.9324 - val_loss: 0.2379\n",
      "Epoch 8/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - acc: 0.9338 - loss: 0.2298 - val_acc: 0.9318 - val_loss: 0.2367\n",
      "Epoch 9/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - acc: 0.9349 - loss: 0.2239 - val_acc: 0.9314 - val_loss: 0.2336\n",
      "Epoch 10/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - acc: 0.9353 - loss: 0.2173 - val_acc: 0.9335 - val_loss: 0.2299\n",
      "Epoch 11/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - acc: 0.9397 - loss: 0.2074 - val_acc: 0.9341 - val_loss: 0.2288\n",
      "Epoch 12/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - acc: 0.9388 - loss: 0.2138 - val_acc: 0.9352 - val_loss: 0.2266\n",
      "Epoch 13/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - acc: 0.9387 - loss: 0.2059 - val_acc: 0.9350 - val_loss: 0.2251\n",
      "Epoch 14/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - acc: 0.9396 - loss: 0.1995 - val_acc: 0.9352 - val_loss: 0.2252\n",
      "Epoch 15/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9410 - loss: 0.1987 - val_acc: 0.9330 - val_loss: 0.2282\n",
      "Epoch 16/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - acc: 0.9418 - loss: 0.1938 - val_acc: 0.9373 - val_loss: 0.2193\n",
      "Epoch 17/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - acc: 0.9436 - loss: 0.1953 - val_acc: 0.9358 - val_loss: 0.2210\n",
      "Epoch 18/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - acc: 0.9437 - loss: 0.1889 - val_acc: 0.9394 - val_loss: 0.2111\n",
      "Epoch 19/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - acc: 0.9421 - loss: 0.1941 - val_acc: 0.9392 - val_loss: 0.2186\n",
      "Epoch 20/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - acc: 0.9454 - loss: 0.1825 - val_acc: 0.9390 - val_loss: 0.2139\n",
      "Epoch 21/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9443 - loss: 0.1872 - val_acc: 0.9404 - val_loss: 0.2117\n",
      "Epoch 22/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - acc: 0.9456 - loss: 0.1818 - val_acc: 0.9352 - val_loss: 0.2241\n",
      "Epoch 23/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 769us/step - acc: 0.9489 - loss: 0.1768 - val_acc: 0.9386 - val_loss: 0.2143\n",
      "Epoch 24/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - acc: 0.9467 - loss: 0.1783 - val_acc: 0.9375 - val_loss: 0.2142\n",
      "Epoch 25/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9485 - loss: 0.1702 - val_acc: 0.9382 - val_loss: 0.2118\n",
      "Epoch 26/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9490 - loss: 0.1725 - val_acc: 0.9402 - val_loss: 0.2083\n",
      "Epoch 27/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - acc: 0.9459 - loss: 0.1769 - val_acc: 0.9390 - val_loss: 0.2139\n",
      "Epoch 28/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9495 - loss: 0.1688 - val_acc: 0.9370 - val_loss: 0.2152\n",
      "Epoch 29/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 821us/step - acc: 0.9502 - loss: 0.1663 - val_acc: 0.9379 - val_loss: 0.2149\n",
      "Epoch 30/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9488 - loss: 0.1737 - val_acc: 0.9389 - val_loss: 0.2110\n",
      "Epoch 31/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9490 - loss: 0.1717 - val_acc: 0.9386 - val_loss: 0.2140\n",
      "Epoch 32/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9494 - loss: 0.1674 - val_acc: 0.9371 - val_loss: 0.2216\n",
      "Epoch 33/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - acc: 0.9516 - loss: 0.1599 - val_acc: 0.9386 - val_loss: 0.2172\n",
      "Epoch 34/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - acc: 0.9524 - loss: 0.1611 - val_acc: 0.9392 - val_loss: 0.2087\n",
      "Epoch 35/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 942us/step - acc: 0.9518 - loss: 0.1609 - val_acc: 0.9344 - val_loss: 0.2267\n",
      "Epoch 36/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - acc: 0.9515 - loss: 0.1634 - val_acc: 0.9408 - val_loss: 0.2103\n",
      "Epoch 37/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - acc: 0.9519 - loss: 0.1592 - val_acc: 0.9404 - val_loss: 0.2111\n",
      "Epoch 38/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9512 - loss: 0.1574 - val_acc: 0.9423 - val_loss: 0.2082\n",
      "Epoch 39/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9554 - loss: 0.1533 - val_acc: 0.9390 - val_loss: 0.2109\n",
      "Epoch 40/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - acc: 0.9526 - loss: 0.1588 - val_acc: 0.9371 - val_loss: 0.2164\n",
      "Epoch 41/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - acc: 0.9537 - loss: 0.1524 - val_acc: 0.9392 - val_loss: 0.2106\n",
      "Epoch 42/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - acc: 0.9513 - loss: 0.1618 - val_acc: 0.9401 - val_loss: 0.2085\n",
      "Epoch 43/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 967us/step - acc: 0.9549 - loss: 0.1522 - val_acc: 0.9400 - val_loss: 0.2111\n",
      "Epoch 44/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - acc: 0.9527 - loss: 0.1552 - val_acc: 0.9358 - val_loss: 0.2180\n",
      "Epoch 45/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - acc: 0.9533 - loss: 0.1548 - val_acc: 0.9379 - val_loss: 0.2116\n",
      "Epoch 46/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - acc: 0.9544 - loss: 0.1546 - val_acc: 0.9381 - val_loss: 0.2162\n",
      "Epoch 47/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - acc: 0.9543 - loss: 0.1523 - val_acc: 0.9387 - val_loss: 0.2150\n",
      "Epoch 48/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - acc: 0.9551 - loss: 0.1484 - val_acc: 0.9389 - val_loss: 0.2121\n",
      "Epoch 49/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - acc: 0.9534 - loss: 0.1545 - val_acc: 0.9384 - val_loss: 0.2106\n",
      "Epoch 50/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9562 - loss: 0.1444 - val_acc: 0.9345 - val_loss: 0.2296\n",
      "Epoch 51/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - acc: 0.9539 - loss: 0.1470 - val_acc: 0.9403 - val_loss: 0.2130\n",
      "Epoch 52/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - acc: 0.9561 - loss: 0.1488 - val_acc: 0.9391 - val_loss: 0.2123\n",
      "Epoch 53/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - acc: 0.9549 - loss: 0.1460 - val_acc: 0.9392 - val_loss: 0.2161\n",
      "Epoch 54/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9538 - loss: 0.1482 - val_acc: 0.9406 - val_loss: 0.2105\n",
      "Epoch 55/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - acc: 0.9555 - loss: 0.1468 - val_acc: 0.9367 - val_loss: 0.2184\n",
      "Epoch 56/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - acc: 0.9559 - loss: 0.1459 - val_acc: 0.9378 - val_loss: 0.2142\n",
      "Epoch 57/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9564 - loss: 0.1450 - val_acc: 0.9367 - val_loss: 0.2139\n",
      "Epoch 58/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - acc: 0.9559 - loss: 0.1445 - val_acc: 0.9401 - val_loss: 0.2117\n",
      "Epoch 59/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - acc: 0.9580 - loss: 0.1435 - val_acc: 0.9380 - val_loss: 0.2127\n",
      "Epoch 60/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9559 - loss: 0.1435 - val_acc: 0.9394 - val_loss: 0.2115\n",
      "Epoch 61/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9576 - loss: 0.1402 - val_acc: 0.9387 - val_loss: 0.2148\n",
      "Epoch 62/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9552 - loss: 0.1449 - val_acc: 0.9391 - val_loss: 0.2147\n",
      "Epoch 63/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - acc: 0.9575 - loss: 0.1380 - val_acc: 0.9355 - val_loss: 0.2206\n",
      "Epoch 64/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - acc: 0.9578 - loss: 0.1403 - val_acc: 0.9398 - val_loss: 0.2141\n",
      "Epoch 65/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - acc: 0.9578 - loss: 0.1404 - val_acc: 0.9348 - val_loss: 0.2279\n",
      "Epoch 66/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - acc: 0.9558 - loss: 0.1447 - val_acc: 0.9386 - val_loss: 0.2165\n",
      "Epoch 67/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - acc: 0.9582 - loss: 0.1364 - val_acc: 0.9386 - val_loss: 0.2157\n",
      "Epoch 68/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9578 - loss: 0.1418 - val_acc: 0.9396 - val_loss: 0.2117\n",
      "Epoch 69/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - acc: 0.9553 - loss: 0.1419 - val_acc: 0.9389 - val_loss: 0.2183\n",
      "Epoch 70/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - acc: 0.9588 - loss: 0.1343 - val_acc: 0.9384 - val_loss: 0.2132\n",
      "Epoch 71/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9569 - loss: 0.1394 - val_acc: 0.9398 - val_loss: 0.2099\n",
      "Epoch 72/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 748us/step - acc: 0.9582 - loss: 0.1351 - val_acc: 0.9370 - val_loss: 0.2178\n",
      "Epoch 73/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - acc: 0.9571 - loss: 0.1381 - val_acc: 0.9375 - val_loss: 0.2167\n",
      "Epoch 74/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - acc: 0.9582 - loss: 0.1358 - val_acc: 0.9402 - val_loss: 0.2121\n",
      "Epoch 75/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - acc: 0.9572 - loss: 0.1365 - val_acc: 0.9392 - val_loss: 0.2185\n",
      "Epoch 76/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - acc: 0.9581 - loss: 0.1357 - val_acc: 0.9391 - val_loss: 0.2144\n",
      "Epoch 77/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - acc: 0.9589 - loss: 0.1342 - val_acc: 0.9405 - val_loss: 0.2135\n",
      "Epoch 78/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 781us/step - acc: 0.9585 - loss: 0.1338 - val_acc: 0.9388 - val_loss: 0.2147\n",
      "Epoch 79/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - acc: 0.9587 - loss: 0.1350 - val_acc: 0.9388 - val_loss: 0.2153\n",
      "Epoch 80/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9585 - loss: 0.1337 - val_acc: 0.9377 - val_loss: 0.2181\n",
      "Epoch 81/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - acc: 0.9584 - loss: 0.1336 - val_acc: 0.9355 - val_loss: 0.2314\n",
      "Epoch 82/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - acc: 0.9567 - loss: 0.1361 - val_acc: 0.9398 - val_loss: 0.2133\n",
      "Epoch 83/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - acc: 0.9600 - loss: 0.1318 - val_acc: 0.9383 - val_loss: 0.2164\n",
      "Epoch 84/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9575 - loss: 0.1376 - val_acc: 0.9365 - val_loss: 0.2182\n",
      "Epoch 85/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - acc: 0.9593 - loss: 0.1291 - val_acc: 0.9397 - val_loss: 0.2184\n",
      "Epoch 86/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - acc: 0.9595 - loss: 0.1285 - val_acc: 0.9399 - val_loss: 0.2152\n",
      "Epoch 87/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - acc: 0.9590 - loss: 0.1313 - val_acc: 0.9381 - val_loss: 0.2157\n",
      "Epoch 88/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - acc: 0.9590 - loss: 0.1344 - val_acc: 0.9392 - val_loss: 0.2174\n",
      "Epoch 89/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - acc: 0.9597 - loss: 0.1336 - val_acc: 0.9374 - val_loss: 0.2179\n",
      "Epoch 90/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - acc: 0.9605 - loss: 0.1306 - val_acc: 0.9388 - val_loss: 0.2167\n",
      "Epoch 91/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - acc: 0.9607 - loss: 0.1297 - val_acc: 0.9377 - val_loss: 0.2217\n",
      "Epoch 92/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9600 - loss: 0.1287 - val_acc: 0.9361 - val_loss: 0.2253\n",
      "Epoch 93/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - acc: 0.9605 - loss: 0.1257 - val_acc: 0.9377 - val_loss: 0.2175\n",
      "Epoch 94/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - acc: 0.9611 - loss: 0.1251 - val_acc: 0.9339 - val_loss: 0.2289\n",
      "Epoch 95/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - acc: 0.9593 - loss: 0.1302 - val_acc: 0.9365 - val_loss: 0.2224\n",
      "Epoch 96/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - acc: 0.9595 - loss: 0.1319 - val_acc: 0.9371 - val_loss: 0.2215\n",
      "Epoch 97/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 849us/step - acc: 0.9615 - loss: 0.1262 - val_acc: 0.9371 - val_loss: 0.2231\n",
      "Epoch 98/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - acc: 0.9611 - loss: 0.1283 - val_acc: 0.9381 - val_loss: 0.2241\n",
      "Epoch 99/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - acc: 0.9603 - loss: 0.1242 - val_acc: 0.9378 - val_loss: 0.2207\n",
      "Epoch 100/100\n",
      "\u001b[1m480/480\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - acc: 0.9604 - loss: 0.1266 - val_acc: 0.9383 - val_loss: 0.2232\n"
     ]
    }
   ],
   "source": [
    "result = model.fit(x_train_scale, y_train, epochs=100, batch_size=100, callbacks=[checkpoint], validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cc30f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 465us/step - acc: 0.9256 - loss: 0.2582\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.23849797248840332, 0.9351000189781189]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ded2f6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi02_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
