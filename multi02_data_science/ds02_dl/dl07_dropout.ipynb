{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4601beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.datasets.mnist import load_data\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13bba818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npy : 1개의 ndarray\n",
    "# npz : 여러 개의 ndarray\n",
    "# 한번 다운된 데이터를 가져다가 쓸려고 할때\n",
    "(x_train, y_train), (x_test, y_test) = load_data(path=\"mnist.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff443e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28), (60000,)\n",
      "(10000, 28, 28), (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(f\"{x_train.shape}, {y_train.shape}\")\n",
    "print(f\"{x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f1b2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MinMaxScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MinMaxScaler</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.preprocessing.MinMaxScaler.html\">?<span>Documentation for MinMaxScaler</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MinMaxScaler()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MinMaxScaler()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaler.fit(x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0283fbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평탄화 작업함  2차원 -> 1차원\n",
    "x_train_scale = scaler.transform(x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2]))\n",
    "x_train_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56ef2f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 784)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_scale = scaler.transform(x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2]))\n",
    "x_test_scale.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2346ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/handaeseong/dev/data-engineer/miniconda3/envs/multi02_tensor/lib/python3.9/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model01 = Sequential([\n",
    "    Dense(8, input_dim=x_train_scale.shape[1], activation=tf.nn.relu),\n",
    "    Dense(64, activation=tf.nn.relu),\n",
    "    Dense(32, activation=tf.nn.relu),\n",
    "    Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c4ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y 데이터를 one-hot encoding 하면 :  categorical_crossentropy\n",
    "# y 데이터가 이산데이터 (그냥 정수)면 : sparse_categorical_crossentropy\n",
    "model01.compile(loss=\"sparse_categorical_crossentropy\", optimizer=SGD(), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b7d5fe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.1433 - loss: 2.2463 - val_acc: 0.5078 - val_loss: 1.7135\n",
      "Epoch 2/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - acc: 0.6120 - loss: 1.3683 - val_acc: 0.7754 - val_loss: 0.7167\n",
      "Epoch 3/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - acc: 0.7849 - loss: 0.6787 - val_acc: 0.8348 - val_loss: 0.5358\n",
      "Epoch 4/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - acc: 0.8385 - loss: 0.5241 - val_acc: 0.8619 - val_loss: 0.4616\n",
      "Epoch 5/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - acc: 0.8625 - loss: 0.4617 - val_acc: 0.8789 - val_loss: 0.4142\n",
      "Epoch 6/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.8807 - loss: 0.4150 - val_acc: 0.8881 - val_loss: 0.3866\n",
      "Epoch 7/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - acc: 0.8864 - loss: 0.3922 - val_acc: 0.8921 - val_loss: 0.3686\n",
      "Epoch 8/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - acc: 0.8920 - loss: 0.3721 - val_acc: 0.8988 - val_loss: 0.3509\n",
      "Epoch 9/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - acc: 0.8998 - loss: 0.3460 - val_acc: 0.9012 - val_loss: 0.3423\n",
      "Epoch 10/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - acc: 0.9008 - loss: 0.3379 - val_acc: 0.9046 - val_loss: 0.3315\n",
      "Epoch 11/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - acc: 0.9053 - loss: 0.3281 - val_acc: 0.9073 - val_loss: 0.3217\n",
      "Epoch 12/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - acc: 0.9073 - loss: 0.3114 - val_acc: 0.9095 - val_loss: 0.3135\n",
      "Epoch 13/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9102 - loss: 0.3060 - val_acc: 0.9112 - val_loss: 0.3069\n",
      "Epoch 14/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9116 - loss: 0.3048 - val_acc: 0.9131 - val_loss: 0.3016\n",
      "Epoch 15/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9124 - loss: 0.3005 - val_acc: 0.9146 - val_loss: 0.2963\n",
      "Epoch 16/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9188 - loss: 0.2809 - val_acc: 0.9147 - val_loss: 0.2916\n",
      "Epoch 17/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9194 - loss: 0.2834 - val_acc: 0.9166 - val_loss: 0.2862\n",
      "Epoch 18/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9232 - loss: 0.2661 - val_acc: 0.9189 - val_loss: 0.2785\n",
      "Epoch 19/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9250 - loss: 0.2585 - val_acc: 0.9210 - val_loss: 0.2742\n",
      "Epoch 20/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - acc: 0.9268 - loss: 0.2560 - val_acc: 0.9208 - val_loss: 0.2734\n",
      "Epoch 21/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - acc: 0.9259 - loss: 0.2615 - val_acc: 0.9207 - val_loss: 0.2719\n",
      "Epoch 22/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - acc: 0.9314 - loss: 0.2432 - val_acc: 0.9238 - val_loss: 0.2629\n",
      "Epoch 23/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - acc: 0.9284 - loss: 0.2459 - val_acc: 0.9254 - val_loss: 0.2577\n",
      "Epoch 24/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - acc: 0.9277 - loss: 0.2494 - val_acc: 0.9267 - val_loss: 0.2558\n",
      "Epoch 25/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9289 - loss: 0.2449 - val_acc: 0.9257 - val_loss: 0.2559\n",
      "Epoch 26/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.9328 - loss: 0.2329 - val_acc: 0.9266 - val_loss: 0.2517\n",
      "Epoch 27/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - acc: 0.9326 - loss: 0.2324 - val_acc: 0.9271 - val_loss: 0.2496\n",
      "Epoch 28/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - acc: 0.9323 - loss: 0.2338 - val_acc: 0.9284 - val_loss: 0.2463\n",
      "Epoch 29/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - acc: 0.9351 - loss: 0.2256 - val_acc: 0.9283 - val_loss: 0.2448\n",
      "Epoch 30/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - acc: 0.9347 - loss: 0.2245 - val_acc: 0.9293 - val_loss: 0.2443\n",
      "Epoch 31/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 963us/step - acc: 0.9331 - loss: 0.2260 - val_acc: 0.9314 - val_loss: 0.2407\n",
      "Epoch 32/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - acc: 0.9369 - loss: 0.2194 - val_acc: 0.9257 - val_loss: 0.2530\n",
      "Epoch 33/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - acc: 0.9344 - loss: 0.2257 - val_acc: 0.9301 - val_loss: 0.2386\n",
      "Epoch 34/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - acc: 0.9395 - loss: 0.2084 - val_acc: 0.9307 - val_loss: 0.2368\n",
      "Epoch 35/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - acc: 0.9378 - loss: 0.2168 - val_acc: 0.9336 - val_loss: 0.2372\n",
      "Epoch 36/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - acc: 0.9402 - loss: 0.2049 - val_acc: 0.9323 - val_loss: 0.2343\n",
      "Epoch 37/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - acc: 0.9384 - loss: 0.2161 - val_acc: 0.9334 - val_loss: 0.2327\n",
      "Epoch 38/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - acc: 0.9403 - loss: 0.2056 - val_acc: 0.9322 - val_loss: 0.2335\n",
      "Epoch 39/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - acc: 0.9403 - loss: 0.2103 - val_acc: 0.9339 - val_loss: 0.2299\n",
      "Epoch 40/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - acc: 0.9408 - loss: 0.2066 - val_acc: 0.9328 - val_loss: 0.2322\n",
      "Epoch 41/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9418 - loss: 0.2012 - val_acc: 0.9342 - val_loss: 0.2273\n",
      "Epoch 42/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - acc: 0.9401 - loss: 0.2036 - val_acc: 0.9343 - val_loss: 0.2270\n",
      "Epoch 43/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - acc: 0.9426 - loss: 0.2003 - val_acc: 0.9339 - val_loss: 0.2291\n",
      "Epoch 44/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - acc: 0.9437 - loss: 0.1952 - val_acc: 0.9347 - val_loss: 0.2238\n",
      "Epoch 45/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - acc: 0.9433 - loss: 0.1961 - val_acc: 0.9341 - val_loss: 0.2243\n",
      "Epoch 46/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9414 - loss: 0.2053 - val_acc: 0.9336 - val_loss: 0.2255\n",
      "Epoch 47/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - acc: 0.9445 - loss: 0.1922 - val_acc: 0.9346 - val_loss: 0.2225\n",
      "Epoch 48/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - acc: 0.9444 - loss: 0.1900 - val_acc: 0.9352 - val_loss: 0.2213\n",
      "Epoch 49/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - acc: 0.9454 - loss: 0.1915 - val_acc: 0.9348 - val_loss: 0.2242\n",
      "Epoch 50/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9438 - loss: 0.1931 - val_acc: 0.9342 - val_loss: 0.2263\n",
      "Epoch 51/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - acc: 0.9442 - loss: 0.1937 - val_acc: 0.9354 - val_loss: 0.2195\n",
      "Epoch 52/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.9442 - loss: 0.1860 - val_acc: 0.9355 - val_loss: 0.2206\n",
      "Epoch 53/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - acc: 0.9455 - loss: 0.1854 - val_acc: 0.9358 - val_loss: 0.2206\n",
      "Epoch 54/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - acc: 0.9459 - loss: 0.1878 - val_acc: 0.9360 - val_loss: 0.2191\n",
      "Epoch 55/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - acc: 0.9458 - loss: 0.1833 - val_acc: 0.9353 - val_loss: 0.2194\n",
      "Epoch 56/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - acc: 0.9459 - loss: 0.1882 - val_acc: 0.9376 - val_loss: 0.2157\n",
      "Epoch 57/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - acc: 0.9457 - loss: 0.1896 - val_acc: 0.9374 - val_loss: 0.2151\n",
      "Epoch 58/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - acc: 0.9447 - loss: 0.1862 - val_acc: 0.9370 - val_loss: 0.2144\n",
      "Epoch 59/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - acc: 0.9474 - loss: 0.1805 - val_acc: 0.9374 - val_loss: 0.2147\n",
      "Epoch 60/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - acc: 0.9474 - loss: 0.1829 - val_acc: 0.9376 - val_loss: 0.2157\n",
      "Epoch 61/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - acc: 0.9484 - loss: 0.1746 - val_acc: 0.9377 - val_loss: 0.2131\n",
      "Epoch 62/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - acc: 0.9474 - loss: 0.1792 - val_acc: 0.9382 - val_loss: 0.2172\n",
      "Epoch 63/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - acc: 0.9479 - loss: 0.1756 - val_acc: 0.9382 - val_loss: 0.2143\n",
      "Epoch 64/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - acc: 0.9492 - loss: 0.1714 - val_acc: 0.9379 - val_loss: 0.2138\n",
      "Epoch 65/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - acc: 0.9494 - loss: 0.1743 - val_acc: 0.9366 - val_loss: 0.2170\n",
      "Epoch 66/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.9486 - loss: 0.1719 - val_acc: 0.9387 - val_loss: 0.2128\n",
      "Epoch 67/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - acc: 0.9478 - loss: 0.1753 - val_acc: 0.9395 - val_loss: 0.2113\n",
      "Epoch 68/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - acc: 0.9478 - loss: 0.1788 - val_acc: 0.9390 - val_loss: 0.2104\n",
      "Epoch 69/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 925us/step - acc: 0.9489 - loss: 0.1749 - val_acc: 0.9343 - val_loss: 0.2214\n",
      "Epoch 70/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - acc: 0.9471 - loss: 0.1776 - val_acc: 0.9376 - val_loss: 0.2139\n",
      "Epoch 71/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - acc: 0.9483 - loss: 0.1756 - val_acc: 0.9388 - val_loss: 0.2097\n",
      "Epoch 72/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - acc: 0.9499 - loss: 0.1691 - val_acc: 0.9378 - val_loss: 0.2151\n",
      "Epoch 73/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - acc: 0.9500 - loss: 0.1733 - val_acc: 0.9387 - val_loss: 0.2110\n",
      "Epoch 74/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - acc: 0.9492 - loss: 0.1730 - val_acc: 0.9396 - val_loss: 0.2091\n",
      "Epoch 75/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - acc: 0.9487 - loss: 0.1746 - val_acc: 0.9379 - val_loss: 0.2119\n",
      "Epoch 76/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - acc: 0.9497 - loss: 0.1677 - val_acc: 0.9402 - val_loss: 0.2073\n",
      "Epoch 77/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9518 - loss: 0.1677 - val_acc: 0.9393 - val_loss: 0.2097\n",
      "Epoch 78/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - acc: 0.9509 - loss: 0.1661 - val_acc: 0.9402 - val_loss: 0.2081\n",
      "Epoch 79/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 897us/step - acc: 0.9516 - loss: 0.1635 - val_acc: 0.9394 - val_loss: 0.2074\n",
      "Epoch 80/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9498 - loss: 0.1681 - val_acc: 0.9407 - val_loss: 0.2109\n",
      "Epoch 81/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - acc: 0.9514 - loss: 0.1657 - val_acc: 0.9397 - val_loss: 0.2075\n",
      "Epoch 82/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - acc: 0.9515 - loss: 0.1628 - val_acc: 0.9402 - val_loss: 0.2079\n",
      "Epoch 83/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - acc: 0.9513 - loss: 0.1627 - val_acc: 0.9384 - val_loss: 0.2123\n",
      "Epoch 84/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - acc: 0.9517 - loss: 0.1638 - val_acc: 0.9396 - val_loss: 0.2073\n",
      "Epoch 85/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - acc: 0.9532 - loss: 0.1592 - val_acc: 0.9407 - val_loss: 0.2056\n",
      "Epoch 86/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - acc: 0.9520 - loss: 0.1643 - val_acc: 0.9403 - val_loss: 0.2108\n",
      "Epoch 87/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - acc: 0.9512 - loss: 0.1632 - val_acc: 0.9392 - val_loss: 0.2087\n",
      "Epoch 88/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - acc: 0.9527 - loss: 0.1596 - val_acc: 0.9396 - val_loss: 0.2080\n",
      "Epoch 89/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - acc: 0.9520 - loss: 0.1638 - val_acc: 0.9394 - val_loss: 0.2101\n",
      "Epoch 90/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - acc: 0.9521 - loss: 0.1575 - val_acc: 0.9408 - val_loss: 0.2073\n",
      "Epoch 91/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - acc: 0.9516 - loss: 0.1643 - val_acc: 0.9395 - val_loss: 0.2078\n",
      "Epoch 92/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - acc: 0.9521 - loss: 0.1601 - val_acc: 0.9411 - val_loss: 0.2046\n",
      "Epoch 93/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - acc: 0.9527 - loss: 0.1590 - val_acc: 0.9403 - val_loss: 0.2074\n",
      "Epoch 94/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - acc: 0.9553 - loss: 0.1511 - val_acc: 0.9395 - val_loss: 0.2088\n",
      "Epoch 95/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - acc: 0.9546 - loss: 0.1526 - val_acc: 0.9401 - val_loss: 0.2067\n",
      "Epoch 96/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - acc: 0.9539 - loss: 0.1572 - val_acc: 0.9419 - val_loss: 0.2052\n",
      "Epoch 97/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - acc: 0.9535 - loss: 0.1582 - val_acc: 0.9402 - val_loss: 0.2071\n",
      "Epoch 98/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - acc: 0.9551 - loss: 0.1480 - val_acc: 0.9392 - val_loss: 0.2099\n",
      "Epoch 99/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - acc: 0.9545 - loss: 0.1517 - val_acc: 0.9393 - val_loss: 0.2085\n",
      "Epoch 100/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - acc: 0.9534 - loss: 0.1551 - val_acc: 0.9408 - val_loss: 0.2046\n"
     ]
    }
   ],
   "source": [
    "result01 = model01.fit(x_train_scale, y_train, epochs=100, validation_split=0.3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a62ae1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 596us/step - acc: 0.9353 - loss: 0.2124\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18942689895629883, 0.9435999989509583]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가하기\n",
    "model01.evaluate(x_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43572cb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/handaeseong/dev/data-engineer/miniconda3/envs/multi02_tensor/lib/python3.9/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Dropout : 다음레이어에 전달하지 않겠다. (과적합 방지)\n",
    "model02 = Sequential([\n",
    "    Dense(8, input_dim=x_train_scale.shape[1], activation=tf.nn.relu),\n",
    "    Dense(64, activation=tf.nn.relu),\n",
    "    Dropout(0.2),\n",
    "    Dense(32, activation=tf.nn.relu),\n",
    "    Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cd3f5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model02.compile(loss=\"sparse_categorical_crossentropy\", optimizer=SGD(), metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac1c790f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.2006 - loss: 2.2168 - val_acc: 0.5180 - val_loss: 1.5727\n",
      "Epoch 2/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 887us/step - acc: 0.5570 - loss: 1.3685 - val_acc: 0.7520 - val_loss: 0.7828\n",
      "Epoch 3/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - acc: 0.7229 - loss: 0.8358 - val_acc: 0.8184 - val_loss: 0.5948\n",
      "Epoch 4/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - acc: 0.7842 - loss: 0.6737 - val_acc: 0.8452 - val_loss: 0.5138\n",
      "Epoch 5/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - acc: 0.8193 - loss: 0.5849 - val_acc: 0.8619 - val_loss: 0.4662\n",
      "Epoch 6/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - acc: 0.8379 - loss: 0.5326 - val_acc: 0.8661 - val_loss: 0.4381\n",
      "Epoch 7/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - acc: 0.8468 - loss: 0.5090 - val_acc: 0.8747 - val_loss: 0.4147\n",
      "Epoch 8/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - acc: 0.8557 - loss: 0.4893 - val_acc: 0.8812 - val_loss: 0.3982\n",
      "Epoch 9/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - acc: 0.8634 - loss: 0.4600 - val_acc: 0.8856 - val_loss: 0.3811\n",
      "Epoch 10/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - acc: 0.8714 - loss: 0.4391 - val_acc: 0.8898 - val_loss: 0.3682\n",
      "Epoch 11/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - acc: 0.8752 - loss: 0.4217 - val_acc: 0.8938 - val_loss: 0.3559\n",
      "Epoch 12/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - acc: 0.8820 - loss: 0.3996 - val_acc: 0.8961 - val_loss: 0.3453\n",
      "Epoch 13/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - acc: 0.8836 - loss: 0.3933 - val_acc: 0.9001 - val_loss: 0.3354\n",
      "Epoch 14/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - acc: 0.8878 - loss: 0.3841 - val_acc: 0.9007 - val_loss: 0.3281\n",
      "Epoch 15/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - acc: 0.8879 - loss: 0.3785 - val_acc: 0.9029 - val_loss: 0.3209\n",
      "Epoch 16/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - acc: 0.8959 - loss: 0.3574 - val_acc: 0.9044 - val_loss: 0.3149\n",
      "Epoch 17/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - acc: 0.8958 - loss: 0.3502 - val_acc: 0.9072 - val_loss: 0.3103\n",
      "Epoch 18/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - acc: 0.9018 - loss: 0.3423 - val_acc: 0.9082 - val_loss: 0.3027\n",
      "Epoch 19/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - acc: 0.8999 - loss: 0.3484 - val_acc: 0.9095 - val_loss: 0.3003\n",
      "Epoch 20/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - acc: 0.9031 - loss: 0.3427 - val_acc: 0.9108 - val_loss: 0.2935\n",
      "Epoch 21/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - acc: 0.9053 - loss: 0.3249 - val_acc: 0.9116 - val_loss: 0.2891\n",
      "Epoch 22/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - acc: 0.9059 - loss: 0.3221 - val_acc: 0.9138 - val_loss: 0.2884\n",
      "Epoch 23/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - acc: 0.9073 - loss: 0.3191 - val_acc: 0.9146 - val_loss: 0.2837\n",
      "Epoch 24/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - acc: 0.9048 - loss: 0.3238 - val_acc: 0.9161 - val_loss: 0.2805\n",
      "Epoch 25/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - acc: 0.9066 - loss: 0.3209 - val_acc: 0.9173 - val_loss: 0.2770\n",
      "Epoch 26/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - acc: 0.9093 - loss: 0.3168 - val_acc: 0.9176 - val_loss: 0.2755\n",
      "Epoch 27/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - acc: 0.9096 - loss: 0.3094 - val_acc: 0.9177 - val_loss: 0.2749\n",
      "Epoch 28/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - acc: 0.9103 - loss: 0.3046 - val_acc: 0.9193 - val_loss: 0.2713\n",
      "Epoch 29/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 866us/step - acc: 0.9126 - loss: 0.3009 - val_acc: 0.9199 - val_loss: 0.2707\n",
      "Epoch 30/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 883us/step - acc: 0.9138 - loss: 0.3005 - val_acc: 0.9199 - val_loss: 0.2685\n",
      "Epoch 31/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - acc: 0.9121 - loss: 0.3015 - val_acc: 0.9203 - val_loss: 0.2651\n",
      "Epoch 32/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - acc: 0.9116 - loss: 0.2957 - val_acc: 0.9214 - val_loss: 0.2662\n",
      "Epoch 33/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - acc: 0.9157 - loss: 0.2864 - val_acc: 0.9219 - val_loss: 0.2625\n",
      "Epoch 34/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - acc: 0.9149 - loss: 0.2922 - val_acc: 0.9219 - val_loss: 0.2637\n",
      "Epoch 35/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - acc: 0.9168 - loss: 0.2829 - val_acc: 0.9224 - val_loss: 0.2622\n",
      "Epoch 36/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - acc: 0.9172 - loss: 0.2795 - val_acc: 0.9224 - val_loss: 0.2597\n",
      "Epoch 37/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 916us/step - acc: 0.9186 - loss: 0.2837 - val_acc: 0.9225 - val_loss: 0.2577\n",
      "Epoch 38/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - acc: 0.9196 - loss: 0.2759 - val_acc: 0.9240 - val_loss: 0.2550\n",
      "Epoch 39/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 856us/step - acc: 0.9191 - loss: 0.2748 - val_acc: 0.9246 - val_loss: 0.2527\n",
      "Epoch 40/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - acc: 0.9196 - loss: 0.2805 - val_acc: 0.9233 - val_loss: 0.2540\n",
      "Epoch 41/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 935us/step - acc: 0.9191 - loss: 0.2711 - val_acc: 0.9243 - val_loss: 0.2525\n",
      "Epoch 42/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - acc: 0.9194 - loss: 0.2791 - val_acc: 0.9254 - val_loss: 0.2513\n",
      "Epoch 43/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - acc: 0.9180 - loss: 0.2745 - val_acc: 0.9241 - val_loss: 0.2535\n",
      "Epoch 44/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - acc: 0.9215 - loss: 0.2676 - val_acc: 0.9256 - val_loss: 0.2478\n",
      "Epoch 45/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - acc: 0.9224 - loss: 0.2653 - val_acc: 0.9252 - val_loss: 0.2501\n",
      "Epoch 46/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - acc: 0.9249 - loss: 0.2637 - val_acc: 0.9253 - val_loss: 0.2459\n",
      "Epoch 47/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - acc: 0.9221 - loss: 0.2644 - val_acc: 0.9257 - val_loss: 0.2485\n",
      "Epoch 48/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - acc: 0.9207 - loss: 0.2705 - val_acc: 0.9262 - val_loss: 0.2439\n",
      "Epoch 49/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - acc: 0.9248 - loss: 0.2631 - val_acc: 0.9282 - val_loss: 0.2425\n",
      "Epoch 50/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - acc: 0.9220 - loss: 0.2574 - val_acc: 0.9280 - val_loss: 0.2403\n",
      "Epoch 51/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - acc: 0.9231 - loss: 0.2533 - val_acc: 0.9280 - val_loss: 0.2405\n",
      "Epoch 52/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - acc: 0.9249 - loss: 0.2538 - val_acc: 0.9290 - val_loss: 0.2387\n",
      "Epoch 53/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 857us/step - acc: 0.9223 - loss: 0.2556 - val_acc: 0.9274 - val_loss: 0.2411\n",
      "Epoch 54/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - acc: 0.9251 - loss: 0.2563 - val_acc: 0.9290 - val_loss: 0.2385\n",
      "Epoch 55/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - acc: 0.9232 - loss: 0.2619 - val_acc: 0.9287 - val_loss: 0.2372\n",
      "Epoch 56/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - acc: 0.9259 - loss: 0.2493 - val_acc: 0.9291 - val_loss: 0.2365\n",
      "Epoch 57/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - acc: 0.9230 - loss: 0.2553 - val_acc: 0.9292 - val_loss: 0.2330\n",
      "Epoch 58/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - acc: 0.9259 - loss: 0.2468 - val_acc: 0.9292 - val_loss: 0.2337\n",
      "Epoch 59/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - acc: 0.9252 - loss: 0.2484 - val_acc: 0.9308 - val_loss: 0.2332\n",
      "Epoch 60/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - acc: 0.9268 - loss: 0.2481 - val_acc: 0.9308 - val_loss: 0.2323\n",
      "Epoch 61/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - acc: 0.9264 - loss: 0.2471 - val_acc: 0.9313 - val_loss: 0.2315\n",
      "Epoch 62/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - acc: 0.9263 - loss: 0.2476 - val_acc: 0.9306 - val_loss: 0.2305\n",
      "Epoch 63/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - acc: 0.9266 - loss: 0.2494 - val_acc: 0.9311 - val_loss: 0.2319\n",
      "Epoch 64/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - acc: 0.9269 - loss: 0.2471 - val_acc: 0.9316 - val_loss: 0.2293\n",
      "Epoch 65/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - acc: 0.9293 - loss: 0.2439 - val_acc: 0.9307 - val_loss: 0.2287\n",
      "Epoch 66/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - acc: 0.9285 - loss: 0.2418 - val_acc: 0.9318 - val_loss: 0.2266\n",
      "Epoch 67/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - acc: 0.9290 - loss: 0.2380 - val_acc: 0.9324 - val_loss: 0.2243\n",
      "Epoch 68/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - acc: 0.9308 - loss: 0.2344 - val_acc: 0.9326 - val_loss: 0.2252\n",
      "Epoch 69/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - acc: 0.9310 - loss: 0.2330 - val_acc: 0.9324 - val_loss: 0.2231\n",
      "Epoch 70/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - acc: 0.9295 - loss: 0.2325 - val_acc: 0.9331 - val_loss: 0.2244\n",
      "Epoch 71/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - acc: 0.9315 - loss: 0.2320 - val_acc: 0.9329 - val_loss: 0.2209\n",
      "Epoch 72/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - acc: 0.9311 - loss: 0.2308 - val_acc: 0.9340 - val_loss: 0.2208\n",
      "Epoch 73/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - acc: 0.9333 - loss: 0.2285 - val_acc: 0.9329 - val_loss: 0.2217\n",
      "Epoch 74/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - acc: 0.9317 - loss: 0.2299 - val_acc: 0.9343 - val_loss: 0.2192\n",
      "Epoch 75/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - acc: 0.9333 - loss: 0.2289 - val_acc: 0.9331 - val_loss: 0.2221\n",
      "Epoch 76/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - acc: 0.9338 - loss: 0.2306 - val_acc: 0.9339 - val_loss: 0.2190\n",
      "Epoch 77/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9322 - loss: 0.2268 - val_acc: 0.9345 - val_loss: 0.2192\n",
      "Epoch 78/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9358 - loss: 0.2174 - val_acc: 0.9352 - val_loss: 0.2186\n",
      "Epoch 79/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996us/step - acc: 0.9318 - loss: 0.2238 - val_acc: 0.9341 - val_loss: 0.2162\n",
      "Epoch 80/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - acc: 0.9349 - loss: 0.2166 - val_acc: 0.9339 - val_loss: 0.2156\n",
      "Epoch 81/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - acc: 0.9344 - loss: 0.2247 - val_acc: 0.9346 - val_loss: 0.2191\n",
      "Epoch 82/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - acc: 0.9357 - loss: 0.2179 - val_acc: 0.9350 - val_loss: 0.2153\n",
      "Epoch 83/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - acc: 0.9358 - loss: 0.2160 - val_acc: 0.9343 - val_loss: 0.2158\n",
      "Epoch 84/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 868us/step - acc: 0.9331 - loss: 0.2212 - val_acc: 0.9349 - val_loss: 0.2141\n",
      "Epoch 85/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - acc: 0.9351 - loss: 0.2169 - val_acc: 0.9362 - val_loss: 0.2136\n",
      "Epoch 86/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 853us/step - acc: 0.9343 - loss: 0.2166 - val_acc: 0.9358 - val_loss: 0.2136\n",
      "Epoch 87/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9320 - loss: 0.2231 - val_acc: 0.9359 - val_loss: 0.2143\n",
      "Epoch 88/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - acc: 0.9358 - loss: 0.2208 - val_acc: 0.9353 - val_loss: 0.2139\n",
      "Epoch 89/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - acc: 0.9353 - loss: 0.2144 - val_acc: 0.9353 - val_loss: 0.2131\n",
      "Epoch 90/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - acc: 0.9335 - loss: 0.2183 - val_acc: 0.9363 - val_loss: 0.2121\n",
      "Epoch 91/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9356 - loss: 0.2134 - val_acc: 0.9359 - val_loss: 0.2119\n",
      "Epoch 92/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - acc: 0.9340 - loss: 0.2149 - val_acc: 0.9359 - val_loss: 0.2120\n",
      "Epoch 93/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - acc: 0.9386 - loss: 0.2064 - val_acc: 0.9349 - val_loss: 0.2117\n",
      "Epoch 94/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 840us/step - acc: 0.9367 - loss: 0.2051 - val_acc: 0.9364 - val_loss: 0.2098\n",
      "Epoch 95/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - acc: 0.9358 - loss: 0.2106 - val_acc: 0.9358 - val_loss: 0.2101\n",
      "Epoch 96/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - acc: 0.9363 - loss: 0.2078 - val_acc: 0.9363 - val_loss: 0.2096\n",
      "Epoch 97/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - acc: 0.9367 - loss: 0.2080 - val_acc: 0.9368 - val_loss: 0.2080\n",
      "Epoch 98/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 851us/step - acc: 0.9374 - loss: 0.2077 - val_acc: 0.9354 - val_loss: 0.2128\n",
      "Epoch 99/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - acc: 0.9364 - loss: 0.2099 - val_acc: 0.9372 - val_loss: 0.2091\n",
      "Epoch 100/100\n",
      "\u001b[1m420/420\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - acc: 0.9366 - loss: 0.2114 - val_acc: 0.9359 - val_loss: 0.2103\n"
     ]
    }
   ],
   "source": [
    "result02 = model02.fit(x_train_scale, y_train, epochs=100, validation_split=0.3, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43c2d4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - acc: 0.9280 - loss: 0.2294\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.21237978339195251, 0.9370999932289124]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model02.evaluate(x_test_scale, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdfca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 히든레이어가 많은 것도 아니고 드랍아웃도 많이 한 것이 아니라서 큰 영향은 없는 것 같다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multi02_tensor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
