{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0220f2b",
   "metadata": {},
   "source": [
    "# EfficientDet - ê³¼ì¼ ë“±ê¸‰ ë¶„ë¥˜ (íŠ¹ìƒ/ìƒ/ì¤‘)\n",
    "## ëª©í‘œ: cate3 ê¸°ë°˜ 3-class Object Detection\n",
    "\n",
    "**Classes:**\n",
    "- 0: íŠ¹ìƒ\n",
    "- 1: ìƒ\n",
    "- 2: ì¤‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "890bd70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.5.1\n",
      "CUDA available: False\n",
      "Base Directory: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits\n",
      "Dataset Directory: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits/datasets\n",
      "Images Directory: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits/datasets/images\n",
      "Labels Directory: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits/datasets/json_labels\n"
     ]
    }
   ],
   "source": [
    "# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "# ê²½ë¡œ ì„¤ì •\n",
    "BASE_DIR = os.path.abspath('..')\n",
    "DATASET_DIR = os.path.join(BASE_DIR, 'datasets')\n",
    "IMAGES_DIR = os.path.join(DATASET_DIR, 'images')\n",
    "LABELS_DIR = os.path.join(DATASET_DIR, 'json_labels')\n",
    "OUTPUT_DIR = os.path.join(BASE_DIR, 'efficientdet', 'outputs')\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Base Directory: {BASE_DIR}\")\n",
    "print(f\"Dataset Directory: {DATASET_DIR}\")\n",
    "print(f\"Images Directory: {IMAGES_DIR}\")\n",
    "print(f\"Labels Directory: {LABELS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d22bdb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ì´ JSON íŒŒì¼ ìˆ˜: 70\n",
      "\n",
      "íŒŒì¼: apple_fuji_M_26-57.json\n",
      "  cate1: ì‚¬ê³¼\n",
      "  cate3: ìƒ\n",
      "  bndbox: {'xmin': 0, 'ymin': 0, 'xmax': 1000, 'ymax': 1000}\n",
      "\n",
      "íŒŒì¼: persimmon_booyu_S_76-26_1TOP.json\n",
      "  cate1: ê°\n",
      "  cate3: ë³´í†µ\n",
      "  bndbox: {'xmin': 0, 'ymin': 0, 'xmax': 1000, 'ymax': 1000}\n",
      "\n",
      "íŒŒì¼: persimmon_booyu_L_76-30_5DI90.json\n",
      "  cate1: ê°\n",
      "  cate3: íŠ¹\n",
      "  bndbox: {'xmin': 0, 'ymin': 0, 'xmax': 1000, 'ymax': 1000}\n",
      "\n",
      "íŒŒì¼: persimmon_booyu_M_76-33_3FR90.json\n",
      "  cate1: ê°\n",
      "  cate3: ìƒ\n",
      "  bndbox: {'xmin': 0, 'ymin': 0, 'xmax': 1000, 'ymax': 1000}\n",
      "\n",
      "íŒŒì¼: apple_fuji_S_26-57.json\n",
      "  cate1: ì‚¬ê³¼\n",
      "  cate3: ë³´í†µ\n",
      "  bndbox: {'xmin': 0, 'ymin': 0, 'xmax': 1000, 'ymax': 1000}\n",
      "\n",
      "=== ë°ì´í„°ì…‹ í†µê³„ (ë“±ê¸‰ ê¸°ì¤€) ===\n",
      "ì´ ì´ë¯¸ì§€ ìˆ˜: 70\n",
      "ì´ ê°ì²´ ìˆ˜: 20\n",
      "  íŠ¹ìƒ: 0ê°œ (0.0%)\n",
      "  ìƒ: 20ê°œ (100.0%)\n",
      "  ì¤‘: 0ê°œ (0.0%)\n"
     ]
    }
   ],
   "source": [
    "# 2. ë°ì´í„°ì…‹ ë¶„ì„ ë° í†µê³„ (cate3 ê¸°ë°˜)\n",
    "def analyze_dataset_cate3():\n",
    "    \"\"\"cate3 (ë“±ê¸‰) ê¸°ë°˜ ë°ì´í„°ì…‹ ë¶„ì„\"\"\"\n",
    "    json_files = glob.glob(os.path.join(LABELS_DIR, '*.json'))\n",
    "    \n",
    "    grade_counts = {'íŠ¹ìƒ': 0, 'ìƒ': 0, 'ì¤‘': 0}\n",
    "    total_boxes = 0\n",
    "    \n",
    "    print(f\"\\nì´ JSON íŒŒì¼ ìˆ˜: {len(json_files)}\")\n",
    "    \n",
    "    for json_file in json_files[:5]:  # ìƒ˜í”Œ 5ê°œ ì¶œë ¥\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            print(f\"\\níŒŒì¼: {os.path.basename(json_file)}\")\n",
    "            print(f\"  cate1: {data.get('cate1', 'N/A')}\")\n",
    "            print(f\"  cate3: {data.get('cate3', 'N/A')}\")\n",
    "            print(f\"  bndbox: {data.get('bndbox', {})}\")\n",
    "    \n",
    "    # ì „ì²´ í†µê³„\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "            cate3 = data.get('cate3', '')\n",
    "            if cate3 in grade_counts:\n",
    "                grade_counts[cate3] += 1\n",
    "                total_boxes += 1\n",
    "    \n",
    "    print(f\"\\n=== ë°ì´í„°ì…‹ í†µê³„ (ë“±ê¸‰ ê¸°ì¤€) ===\")\n",
    "    print(f\"ì´ ì´ë¯¸ì§€ ìˆ˜: {len(json_files)}\")\n",
    "    print(f\"ì´ ê°ì²´ ìˆ˜: {total_boxes}\")\n",
    "    for grade, count in grade_counts.items():\n",
    "        print(f\"  {grade}: {count}ê°œ ({count/total_boxes*100:.1f}%)\")\n",
    "    \n",
    "    return grade_counts\n",
    "\n",
    "stats = analyze_dataset_cate3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd7658d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ë°ì´í„° ë¶„í• :\n",
      "  Train: 56ê°œ\n",
      "  Val: 14ê°œ\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting train: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 56/56 [00:00<00:00, 480.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train - Images: 56, Annotations: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Converting val: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 14/14 [00:00<00:00, 2132.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val - Images: 14, Annotations: 3\n",
      "\n",
      "âœ… COCO íŒŒì¼ ìƒì„± ì™„ë£Œ:\n",
      "  Train: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits/efficientdet/outputs/train_cate3.json\n",
      "  Val: /Users/handaeseong/dev/data-engineer/workspaces/z-mini_project/fruits/efficientdet/outputs/val_cate3.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. COCO í˜•ì‹ ë°ì´í„°ì…‹ ë³€í™˜ (cate3 ê¸°ë°˜)\n",
    "class FruitGradeDatasetConverter:\n",
    "    \"\"\"JSON to COCO format converter for cate3 (grade)\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, labels_dir, output_dir):\n",
    "        self.images_dir = images_dir\n",
    "        self.labels_dir = labels_dir\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        # cate3 ê¸°ë°˜ í´ë˜ìŠ¤ ë§¤í•‘\n",
    "        self.class_map = {\n",
    "            'íŠ¹ìƒ': 0,\n",
    "            'ìƒ': 1,\n",
    "            'ì¤‘': 2\n",
    "        }\n",
    "        self.classes = ['íŠ¹ìƒ', 'ìƒ', 'ì¤‘']\n",
    "        \n",
    "    def convert_to_coco(self, split_ratio=0.8):\n",
    "        \"\"\"COCO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ ë° train/val ë¶„í• \"\"\"\n",
    "        \n",
    "        json_files = sorted(glob.glob(os.path.join(self.labels_dir, '*.json')))\n",
    "        np.random.seed(42)\n",
    "        np.random.shuffle(json_files)\n",
    "        \n",
    "        split_idx = int(len(json_files) * split_ratio)\n",
    "        train_files = json_files[:split_idx]\n",
    "        val_files = json_files[split_idx:]\n",
    "        \n",
    "        print(f\"\\në°ì´í„° ë¶„í• :\")\n",
    "        print(f\"  Train: {len(train_files)}ê°œ\")\n",
    "        print(f\"  Val: {len(val_files)}ê°œ\")\n",
    "        \n",
    "        # Train/Val ê°ê° ë³€í™˜\n",
    "        train_coco = self._create_coco_dataset(train_files, 'train')\n",
    "        val_coco = self._create_coco_dataset(val_files, 'val')\n",
    "        \n",
    "        # ì €ì¥\n",
    "        train_json_path = os.path.join(self.output_dir, 'train_cate3.json')\n",
    "        val_json_path = os.path.join(self.output_dir, 'val_cate3.json')\n",
    "        \n",
    "        with open(train_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(train_coco, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        with open(val_json_path, 'w', encoding='utf-8') as f:\n",
    "            json.dump(val_coco, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        print(f\"\\nâœ… COCO íŒŒì¼ ìƒì„± ì™„ë£Œ:\")\n",
    "        print(f\"  Train: {train_json_path}\")\n",
    "        print(f\"  Val: {val_json_path}\")\n",
    "        \n",
    "        return train_json_path, val_json_path\n",
    "    \n",
    "    def _create_coco_dataset(self, json_files, split_name):\n",
    "        \"\"\"COCO ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±\"\"\"\n",
    "        \n",
    "        coco_dataset = {\n",
    "            \"images\": [],\n",
    "            \"annotations\": [],\n",
    "            \"categories\": []\n",
    "        }\n",
    "        \n",
    "        # Categories ì¶”ê°€\n",
    "        for idx, class_name in enumerate(self.classes):\n",
    "            coco_dataset[\"categories\"].append({\n",
    "                \"id\": idx,\n",
    "                \"name\": class_name,\n",
    "                \"supercategory\": \"grade\"\n",
    "            })\n",
    "        \n",
    "        annotation_id = 0\n",
    "        \n",
    "        for image_id, json_file in enumerate(tqdm(json_files, desc=f\"Converting {split_name}\")):\n",
    "            with open(json_file, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            # ì´ë¯¸ì§€ íŒŒì¼ëª…\n",
    "            img_filename = os.path.basename(json_file).replace('.json', '.png')\n",
    "            img_path = os.path.join(self.images_dir, img_filename)\n",
    "            \n",
    "            if not os.path.exists(img_path):\n",
    "                continue\n",
    "            \n",
    "            # ì´ë¯¸ì§€ ì •ë³´\n",
    "            img = Image.open(img_path)\n",
    "            width, height = img.size\n",
    "            \n",
    "            coco_dataset[\"images\"].append({\n",
    "                \"id\": image_id,\n",
    "                \"file_name\": img_filename,\n",
    "                \"width\": width,\n",
    "                \"height\": height\n",
    "            })\n",
    "            \n",
    "            # Annotation ì¶”ê°€\n",
    "            cate3 = data.get('cate3', '')\n",
    "            if cate3 not in self.class_map:\n",
    "                continue\n",
    "            \n",
    "            bbox = data.get('bndbox', {})\n",
    "            xmin = float(bbox.get('xmin', 0))\n",
    "            ymin = float(bbox.get('ymin', 0))\n",
    "            xmax = float(bbox.get('xmax', width))\n",
    "            ymax = float(bbox.get('ymax', height))\n",
    "            \n",
    "            bbox_width = xmax - xmin\n",
    "            bbox_height = ymax - ymin\n",
    "            area = bbox_width * bbox_height\n",
    "            \n",
    "            coco_dataset[\"annotations\"].append({\n",
    "                \"id\": annotation_id,\n",
    "                \"image_id\": image_id,\n",
    "                \"category_id\": self.class_map[cate3],\n",
    "                \"bbox\": [xmin, ymin, bbox_width, bbox_height],\n",
    "                \"area\": area,\n",
    "                \"iscrowd\": 0\n",
    "            })\n",
    "            \n",
    "            annotation_id += 1\n",
    "        \n",
    "        print(f\"{split_name} - Images: {len(coco_dataset['images'])}, Annotations: {len(coco_dataset['annotations'])}\")\n",
    "        \n",
    "        return coco_dataset\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë³€í™˜ ì‹¤í–‰\n",
    "converter = FruitGradeDatasetConverter(IMAGES_DIR, LABELS_DIR, OUTPUT_DIR)\n",
    "train_json, val_json = converter.convert_to_coco(split_ratio=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c2b8ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:\n",
      "  Train ìƒ˜í”Œ ìˆ˜: 56\n",
      "  Val ìƒ˜í”Œ ìˆ˜: 14\n"
     ]
    }
   ],
   "source": [
    "# 4. PyTorch Dataset í´ë˜ìŠ¤\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "class COCOGradeDataset(Dataset):\n",
    "    \"\"\"COCO í˜•ì‹ ë“±ê¸‰ ë°ì´í„°ì…‹\"\"\"\n",
    "    \n",
    "    def __init__(self, images_dir, coco_json_path, transform=None):\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        with open(coco_json_path, 'r') as f:\n",
    "            self.coco_data = json.load(f)\n",
    "        \n",
    "        self.images = self.coco_data['images']\n",
    "        self.annotations = self.coco_data['annotations']\n",
    "        \n",
    "        # image_idë¥¼ í‚¤ë¡œ í•˜ëŠ” annotations ë”•ì…”ë„ˆë¦¬ ìƒì„±\n",
    "        self.img_to_anns = {}\n",
    "        for ann in self.annotations:\n",
    "            img_id = ann['image_id']\n",
    "            if img_id not in self.img_to_anns:\n",
    "                self.img_to_anns[img_id] = []\n",
    "            self.img_to_anns[img_id].append(ann)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_info = self.images[idx]\n",
    "        img_path = os.path.join(self.images_dir, img_info['file_name'])\n",
    "        \n",
    "        # ì´ë¯¸ì§€ ë¡œë“œ\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        \n",
    "        # Annotations ê°€ì ¸ì˜¤ê¸°\n",
    "        img_id = img_info['id']\n",
    "        anns = self.img_to_anns.get(img_id, [])\n",
    "        \n",
    "        boxes = []\n",
    "        labels = []\n",
    "        \n",
    "        for ann in anns:\n",
    "            x, y, w, h = ann['bbox']\n",
    "            boxes.append([x, y, x + w, y + h])\n",
    "            labels.append(ann['category_id'])\n",
    "        \n",
    "        boxes = np.array(boxes, dtype=np.float32)\n",
    "        labels = np.array(labels, dtype=np.int64)\n",
    "        \n",
    "        target = {\n",
    "            'boxes': boxes,\n",
    "            'labels': labels,\n",
    "            'image_id': img_id\n",
    "        }\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, target\n",
    "\n",
    "# Transform ì •ì˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((512, 512)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# ë°ì´í„°ì…‹ ë° DataLoader ìƒì„±\n",
    "train_dataset = COCOGradeDataset(IMAGES_DIR, train_json, transform=transform)\n",
    "val_dataset = COCOGradeDataset(IMAGES_DIR, val_json, transform=transform)\n",
    "\n",
    "print(f\"\\nâœ… ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ:\")\n",
    "print(f\"  Train ìƒ˜í”Œ ìˆ˜: {len(train_dataset)}\")\n",
    "print(f\"  Val ìƒ˜í”Œ ìˆ˜: {len(val_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61daa0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unexpected keys (bn2.num_batches_tracked, bn2.bias, bn2.running_mean, bn2.running_var, bn2.weight, classifier.bias, classifier.weight, conv_head.weight) found while loading pretrained weights. This may be expected if model is being adapted.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… EfficientDet-D1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë“±ê¸‰ ë¶„ë¥˜)\n",
      "  Device: cpu\n",
      "  Input size: [512, 512]\n",
      "  Classes: 3 (íŠ¹ìƒ, ìƒ, ì¤‘)\n"
     ]
    }
   ],
   "source": [
    "# 5. EfficientDet ëª¨ë¸ ë¡œë“œ\n",
    "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
    "from effdet.efficientdet import HeadNet\n",
    "\n",
    "def create_model(num_classes=3):\n",
    "    \"\"\"EfficientDet-D1 ëª¨ë¸ ìƒì„± (ë“±ê¸‰ ë¶„ë¥˜)\"\"\"\n",
    "    \n",
    "    config = get_efficientdet_config('tf_efficientdet_d1')\n",
    "    config.num_classes = num_classes\n",
    "    config.image_size = (512, 512)\n",
    "    \n",
    "    net = EfficientDet(config, pretrained_backbone=True)\n",
    "    net.class_net = HeadNet(\n",
    "        config,\n",
    "        num_outputs=config.num_classes,\n",
    "    )\n",
    "    \n",
    "    model = DetBenchTrain(net, config)\n",
    "    \n",
    "    return model, config\n",
    "\n",
    "model, config = create_model(num_classes=3)\n",
    "device = torch.device('cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "print(f\"\\nâœ… EfficientDet-D1 ëª¨ë¸ ë¡œë“œ ì™„ë£Œ (ë“±ê¸‰ ë¶„ë¥˜)\")\n",
    "print(f\"  Device: {device}\")\n",
    "print(f\"  Input size: {config.image_size}\")\n",
    "print(f\"  Classes: {config.num_classes} (íŠ¹ìƒ, ìƒ, ì¤‘)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "702e945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… DataLoader ìƒì„± ì™„ë£Œ\n",
      "  Train batches: 14\n",
      "  Val batches: 4\n"
     ]
    }
   ],
   "source": [
    "# 6. í•™ìŠµ í•¨ìˆ˜\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "def collate_fn(batch):\n",
    "    \"\"\"ë°°ì¹˜ ë°ì´í„° collate í•¨ìˆ˜\"\"\"\n",
    "    images = []\n",
    "    targets = []\n",
    "    \n",
    "    for img, target in batch:\n",
    "        images.append(img)\n",
    "        targets.append(target)\n",
    "    \n",
    "    images = torch.stack(images, dim=0)\n",
    "    \n",
    "    return images, targets\n",
    "\n",
    "def train_one_epoch(model, dataloader, optimizer, device, epoch):\n",
    "    \"\"\"1 ì—í­ í•™ìŠµ\"\"\"\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    progress_bar = tqdm(dataloader, desc=f\"Epoch {epoch+1}\")\n",
    "    \n",
    "    for images, targets in progress_bar:\n",
    "        images = images.to(device)\n",
    "        \n",
    "        target_dict = {\n",
    "            'bbox': [],\n",
    "            'cls': []\n",
    "        }\n",
    "        \n",
    "        for target in targets:\n",
    "            boxes = torch.tensor(target['boxes'], dtype=torch.float32)\n",
    "            labels = torch.tensor(target['labels'], dtype=torch.int64)\n",
    "            \n",
    "            target_dict['bbox'].append(boxes)\n",
    "            target_dict['cls'].append(labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        try:\n",
    "            loss, _, _ = model(images, target_dict)\n",
    "            loss = loss.mean()\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸  ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}\")\n",
    "            continue\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n",
    "\n",
    "# DataLoader ìƒì„±\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=4,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… DataLoader ìƒì„± ì™„ë£Œ\")\n",
    "print(f\"  Train batches: {len(train_loader)}\")\n",
    "print(f\"  Val batches: {len(val_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e984430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ í•™ìŠµ ì‹œì‘ (ë“±ê¸‰ ë¶„ë¥˜)...\n",
      "  Epochs: 50\n",
      "  Learning Rate: 0.0001\n",
      "  Classes: íŠ¹ìƒ, ìƒ, ì¤‘\n",
      "\n",
      "============================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|â–‹         | 1/14 [00:03<00:44,  3.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âš ï¸  ë°°ì¹˜ ì²˜ë¦¬ ì¤‘ ì—ëŸ¬ ë°œìƒ: Invalid dimensions for box data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   7%|â–‹         | 1/14 [00:06<01:30,  6.98s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m best_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NUM_EPOCHS):\n\u001b[0;32m---> 18\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[1;32m     21\u001b[0m     scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "Cell \u001b[0;32mIn[7], line 43\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, optimizer, device, epoch)\u001b[0m\n\u001b[1;32m     40\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 43\u001b[0m     loss, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()\n\u001b[1;32m     46\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/effdet/bench.py:157\u001b[0m, in \u001b[0;36mDetBenchTrain.forward\u001b[0;34m(self, x, target)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, target: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]):\n\u001b[0;32m--> 157\u001b[0m     class_out, box_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39manchor_labeler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# target should contain pre-computed anchor labels if labeler not present in bench\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel_num_positives\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m target\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/effdet/efficientdet.py:732\u001b[0m, in \u001b[0;36mEfficientDet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    730\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackbone(x)\n\u001b[1;32m    731\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfpn(x)\n\u001b[0;32m--> 732\u001b[0m x_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    733\u001b[0m x_box \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbox_net(x)\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_class, x_box\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/effdet/efficientdet.py:564\u001b[0m, in \u001b[0;36mHeadNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_level_first(x)\n\u001b[1;32m    563\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 564\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/effdet/efficientdet.py:546\u001b[0m, in \u001b[0;36mHeadNet._forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    544\u001b[0m         x_level \u001b[38;5;241m=\u001b[39m bn[level](x_level)  \u001b[38;5;66;03m# this is not allowed in torchscript\u001b[39;00m\n\u001b[1;32m    545\u001b[0m         x_level \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mact(x_level)\n\u001b[0;32m--> 546\u001b[0m     outputs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_level\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/effdet/efficientdet.py:115\u001b[0m, in \u001b[0;36mSeparableConv2d.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 115\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_dw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv_pw(x)\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/dev/data-engineer/miniconda3/envs/effdet_env/lib/python3.10/site-packages/torch/nn/modules/conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[1;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[1;32m    548\u001b[0m     )\n\u001b[0;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[1;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 7. í•™ìŠµ ì‹¤í–‰\n",
    "NUM_EPOCHS = 50\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=NUM_EPOCHS, eta_min=1e-6)\n",
    "\n",
    "print(f\"\\nğŸš€ í•™ìŠµ ì‹œì‘ (ë“±ê¸‰ ë¶„ë¥˜)...\")\n",
    "print(f\"  Epochs: {NUM_EPOCHS}\")\n",
    "print(f\"  Learning Rate: {LEARNING_RATE}\")\n",
    "print(f\"  Classes: íŠ¹ìƒ, ìƒ, ì¤‘\")\n",
    "print(f\"\\n{'='*60}\\n\")\n",
    "\n",
    "train_losses = []\n",
    "best_loss = float('inf')\n",
    "\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer, device, epoch)\n",
    "    train_losses.append(train_loss)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{NUM_EPOCHS} - Loss: {train_loss:.4f} - LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
    "    \n",
    "    if train_loss < best_loss:\n",
    "        best_loss = train_loss\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "        }, os.path.join(OUTPUT_DIR, 'best_efficientdet_cate3.pth'))\n",
    "        print(f\"  âœ… Best ëª¨ë¸ ì €ì¥ (Loss: {best_loss:.4f})\")\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': train_loss,\n",
    "        }, os.path.join(OUTPUT_DIR, f'efficientdet_cate3_epoch{epoch+1}.pth'))\n",
    "        print(f\"  ğŸ’¾ Checkpoint ì €ì¥ (Epoch {epoch+1})\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"\\nğŸ‰ í•™ìŠµ ì™„ë£Œ!\")\n",
    "print(f\"  Best Loss: {best_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04280a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. í•™ìŠµ ê²°ê³¼ ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss', linewidth=2, color='orange')\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('EfficientDet-D1 Training Loss (cate3 - ë“±ê¸‰)', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=10)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "\n",
    "plot_path = os.path.join(OUTPUT_DIR, 'training_loss_cate3.png')\n",
    "plt.savefig(plot_path, dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nâœ… í•™ìŠµ ê·¸ë˜í”„ ì €ì¥: {plot_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9370cfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. ì¶”ë¡  ë° ì‹œê°í™”\n",
    "def visualize_predictions(model, dataset, device, num_samples=5):\n",
    "    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ì‹œê°í™”\"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    class_names = ['íŠ¹ìƒ', 'ìƒ', 'ì¤‘']\n",
    "    colors = ['gold', 'silver', 'brown']\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(min(num_samples, len(dataset))):\n",
    "            img, target = dataset[i]\n",
    "            \n",
    "            img_tensor = img.unsqueeze(0).to(device)\n",
    "            output = model(img_tensor)\n",
    "            \n",
    "            img_np = img.cpu().numpy().transpose(1, 2, 0)\n",
    "            img_np = img_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
    "            img_np = np.clip(img_np, 0, 1)\n",
    "            \n",
    "            axes[i].imshow(img_np)\n",
    "            axes[i].axis('off')\n",
    "            axes[i].set_title(f'Sample {i+1}', fontsize=10, fontweight='bold')\n",
    "            \n",
    "            gt_boxes = target['boxes']\n",
    "            gt_labels = target['labels']\n",
    "            \n",
    "            for box, label in zip(gt_boxes, gt_labels):\n",
    "                x1, y1, x2, y2 = box\n",
    "                width, height = 512, 512\n",
    "                x1, x2 = x1 * width / 512, x2 * width / 512\n",
    "                y1, y2 = y1 * height / 512, y2 * height / 512\n",
    "                \n",
    "                rect = plt.Rectangle(\n",
    "                    (x1, y1), x2 - x1, y2 - y1,\n",
    "                    fill=False, color=colors[label], linewidth=2\n",
    "                )\n",
    "                axes[i].add_patch(rect)\n",
    "                axes[i].text(\n",
    "                    x1, y1 - 5,\n",
    "                    f'{class_names[label]}',\n",
    "                    color=colors[label],\n",
    "                    fontsize=9,\n",
    "                    fontweight='bold',\n",
    "                    bbox=dict(boxstyle='round', facecolor='white', alpha=0.7)\n",
    "                )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    viz_path = os.path.join(OUTPUT_DIR, 'predictions_cate3.png')\n",
    "    plt.savefig(viz_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"\\nâœ… ì˜ˆì¸¡ ì‹œê°í™” ì €ì¥: {viz_path}\")\n",
    "\n",
    "visualize_predictions(model, val_dataset, device, num_samples=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e9545",
   "metadata": {},
   "source": [
    "## âœ… effi02.ipynb ì™„ë£Œ!\n",
    "\n",
    "### í•™ìŠµ ì™„ë£Œ:\n",
    "- ëª¨ë¸: EfficientDet-D1\n",
    "- í´ë˜ìŠ¤: 3ê°œ (íŠ¹ìƒ, ìƒ, ì¤‘)\n",
    "- ì €ì¥ ìœ„ì¹˜: `efficientdet/outputs/best_efficientdet_cate3.pth`\n",
    "\n",
    "### ë‹¤ìŒ:\n",
    "- **effi03.ipynb**: í†µí•© ë¶„ë¥˜ (9 classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "effdet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
