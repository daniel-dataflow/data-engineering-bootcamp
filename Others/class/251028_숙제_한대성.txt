DTM (Document-Term Matrix, 문서 단어 행렬)은 텍스트 데이터를 기계 학습 모델이 처리할 수 있도록 수치형 특성 벡터(feature vector)로 변환하는 기본적인 방법입니다. 
텍스트 자체를 분석하는 것이 아니라, 텍스트에 포함된 단어의 빈도를 기반으로 문서를 표현하는 "Bag-of-Words (BoW)" 접근 방식을 행렬로 구현한 것입니다.

1. DTM의 정의 및 목적
DTM은 이름 그대로 문서(Document)를 행(row)으로, 단어(Term)를 열(column)로 하는 2차원 행렬입니다.
- 행 (Rows): 분석 대상이 되는 개별 문서 (예: 이메일, 뉴스 기사, 리뷰)
- 열 (Columns):" 전체 문서 모음(corpus)에서 추출된 고유한 단어의 집합 (Vocabulary, 단어장)
- 값 (Values): 특정 문서(행)에 특정 단어(열)가 등장한 횟수 (Frequency)

목적: 비정형 텍스트 데이터를 정형화된 숫자 행렬로 변환하여, 텍스트 분류, 군집화, 토픽 모델링 등 다양한 기계 학습 알고리즘의 입력값으로 사용하기 위함입니다.

2. DTM 생성 과정 (scikit-learn CountVectorizer 기준)
파이썬의 scikit-learn 라이브러리에서 DTM은 CountVectorizer 클래스를 통해 생성됩니다. 이 과정은 크게 3단계로 이루어집니다.

	1단계: 토큰화 (Tokenization)
		문서 텍스트를 정규표현식이나 특정 규칙에 따라 더 작은 단위인 **토큰(token)**으로 분리합니다.
		기본적으로는 공백이나 문장 부호를 기준으로 단어를 분리하며, 사용자가 정의한 tokenizer를 사용할 수도 있습니다.

	2단계: 단어장 구축 (Vocabulary Building)
	모든 문서에서 추출된 토큰들을 모아 고유한 단어의 집합(단어장)을 만듭니다.
	이 과정에서 단어장에 포함될 단어를 제어하기 위해 다음과 같은 중요한 파라미터가 사용됩니다.
		-stop_words: 'a', 'the' 또는 '은', '는' 등 의미에 큰 영향을 주지 않는 불용어를 단어장에서 제외합니다.
		min_df: 단어가 최소 N개의 문서(또는 전체 문서의 M% 비율) 이상에서 등장해야 단어장에 포함시킵니다. (너무 드문 단어 제거)
		max_df: 단어가 최대 N개의 문서(또는 전체 문서의 M% 비율) 이하에서 등장해야 단어장에 포함시킵니다. (너무 흔한 단어 제거)
		max_features: 가장 빈도가 높은 순서대로 최대 N개의 단어만 단어장에 포함시킵니다. (행렬의 크기(차원) 제어)
		ngram_range: (예: (1, 2)) 'word' 같은 단일 토큰(1-gram)뿐만 아니라, 'New York' 같은 연속된 2개 단어(2-gram)까지 토큰으로 인식해 단어장에 포함시킵니다.

	3단계: 카운팅 및 행렬 생성 (Counting & Matrix Generation)
		구축된 단어장을 기준으로, 각 문서에 단어장의 단어들이 몇 번씩 등장했는지 횟수를 셉니다.
		이 결과를 바탕으로 (문서 수) $\times$ (단어장 크기) 차원의 DTM을 생성합니다.

3. DTM의 주요 특징: 희소 행렬 (Sparse Matrix)
실제 텍스트 데이터에서 단어장의 크기는 수만에서 수십만 개에 달할 수 있습니다. 하지만 하나의 문서는 그중 극히 일부의 단어만 포함합니다.
	결과: DTM은 대부분의 값이 0으로 채워진 거대한 행렬이 됩니다.
	해결: 메모리 낭비를 막기 위해, scikit-learn과 같은 라이브러리는 DTM을 일반적인 2차원 배열(Numpy array)이 아니라, 0이 아닌 값의 위치와 값만 저장하는 희소 행렬 (Sparse Matrix) 형식(예: SciPy의 csr_matrix)으로 반환합니다. 이는 저장 공간과 계산 속도 면에서 매우 효율적입니다.

4. DTM의 한계점 (공식 문서에서 언급되는 대안)
DTM은 구현이 간단하지만 다음과 같은 명확한 한계가 있습니다.
	- 차원의 저주 (Curse of Dimensionality): 단어장의 크기(열의 개수)가 문서 수(행의 개수)에 비해 매우 커져 계산이 비효율적이거나 모델 성능이 저하될 수 있습니다. (이는 max_features 등으로 제어)
	- 단순 빈도의 문제: 'the'처럼 모든 문서에 자주 등장하지만 중요도는 낮은 단어의 영향력이 과도하게 반영될 수 있습니다.
	- 문맥 정보의 부재: 단어의 순서나 문맥적 의미를 전혀 고려하지 않습니다. (Bag-of-Words의 근본적인 한계)
이러한 한계, 특히 2번 문제(단순 빈도 문제)를 보완하기 위해 공식 문서에서는 DTM의 대안으로 **TF-IDF (Term Frequency-Inverse Document Frequency)**를 함께 소개합니다.

TF-IDF (TfidfVectorizer): DTM의 '단순 카운트' 값 대신, '해당 문서에서는 자주 등장하지만(TF), 전체 문서에서는 드물게 등장하는(IDF)' 단어에 더 높은 가중치를 부여하는 TF-IDF 값으로 행렬을 채웁니다. 이는 DTM보다 단어의 중요도를 더 잘 반영하는 경향이 있습니다.